{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary 3: Deep Learning Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter contains model architectures of all deep learning models fitted in the project. Complete scripts used to train the models can be found in the following git repository: GIT LINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 CNN on single images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first used single frames obtained from Deep Meerkat and fitted a simple CNN as well as using VGG19 for transfer learning.The model architectures can be seen below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "conv2d_1 (Conv2D)                   (None, 125, 69, 20)             980         \n",
      "________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)      (None, 41, 23, 20)              0           \n",
      "________________________________________________________________________________\n",
      "flatten_2 (Flatten)                 (None, 18860)                   0           \n",
      "________________________________________________________________________________\n",
      "dense_5 (Dense)                     (None, 64)                      1207104     \n",
      "________________________________________________________________________________\n",
      "dense_6 (Dense)                     (None, 32)                      2080        \n",
      "________________________________________________________________________________\n",
      "dropout_3 (Dropout)                 (None, 32)                      0           \n",
      "________________________________________________________________________________\n",
      "dense_7 (Dense)                     (None, 1)                       33          \n",
      "================================================================================\n",
      "Total params: 1,210,197\n",
      "Trainable params: 1,210,197\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN <- keras_model_sequential()\n",
    "\n",
    "CNN %>% layer_conv_2d(filters=20, kernel_size=c(4,4), activation = 'relu',\n",
    "                      input_shape=c(128,72,3), data_format=\"channels_last\") %>%\n",
    "  layer_max_pooling_2d(pool_size = c(3,3)) %>%\n",
    "  layer_flatten() %>%\n",
    "  layer_dense(units=64, activation = 'relu')%>%\n",
    "  layer_dense(units=32, activation='relu')%>%\n",
    "  layer_dropout(rate=0.2) %>%\n",
    "  layer_dense(units=1, activation='sigmoid')%>%\n",
    "  compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=c('accuracy')\n",
    "  )\n",
    "\n",
    "summary(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning using VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "vgg19 (Functional)                  (None, 4, 2, 512)               20024384    \n",
      "________________________________________________________________________________\n",
      "dropout_4 (Dropout)                 (None, 4, 2, 512)               0           \n",
      "________________________________________________________________________________\n",
      "flatten_3 (Flatten)                 (None, 4096)                    0           \n",
      "________________________________________________________________________________\n",
      "dense_8 (Dense)                     (None, 32)                      131104      \n",
      "________________________________________________________________________________\n",
      "dropout_5 (Dropout)                 (None, 32)                      0           \n",
      "________________________________________________________________________________\n",
      "dense_9 (Dense)                     (None, 1)                       33          \n",
      "================================================================================\n",
      "Total params: 20,155,521\n",
      "Trainable params: 20,155,521\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VGG19 <- application_vgg19(include_top = FALSE, weights=\"imagenet\", input_shape = c(128,72,3))\n",
    "VGGModel <- keras_model_sequential()%>%\n",
    "    VGG19 %>%\n",
    "    layer_dropout(rate=0.5)%>%\n",
    "    layer_flatten()%>%\n",
    "    layer_dense(units=32, activation='relu')%>%\n",
    "    layer_dropout(rate=0.2)%>%\n",
    "    layer_dense(units=1, activation='sigmoid') %>%\n",
    "    compile(\n",
    "      optimizer=optimizer_adam(lr=1e-05),\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=c('accuracy')\n",
    "    )\n",
    "summary(VGGModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 RNN on stacked images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training models on single images, I stacked 4 images at a time and used a recurrent layer to evaluate all the frames together. The same approach was used for both sex and behaviour classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv-LSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)           (None, 30, 118, 70)             35760       \n",
      "________________________________________________________________________________\n",
      "dropout_6 (Dropout)                 (None, 30, 118, 70)             0           \n",
      "________________________________________________________________________________\n",
      "flatten_4 (Flatten)                 (None, 247800)                  0           \n",
      "________________________________________________________________________________\n",
      "dense_10 (Dense)                    (None, 64)                      15859264    \n",
      "________________________________________________________________________________\n",
      "dropout_7 (Dropout)                 (None, 64)                      0           \n",
      "________________________________________________________________________________\n",
      "dense_11 (Dense)                    (None, 32)                      2080        \n",
      "________________________________________________________________________________\n",
      "dropout_8 (Dropout)                 (None, 32)                      0           \n",
      "________________________________________________________________________________\n",
      "dense_12 (Dense)                    (None, 1)                       33          \n",
      "================================================================================\n",
      "Total params: 15,897,137\n",
      "Trainable params: 15,897,137\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN <- keras_model_sequential()\n",
    "\n",
    "RNN %>% layer_conv_lstm_2d(filters=30, kernel_size = c(3,3), \n",
    "                           input_shape = c(4,3,120,72), \n",
    "                           data_format = \"channels_first\", return_sequences = FALSE,\n",
    "                           activation=\"relu\") %>%\n",
    "  layer_dropout(rate=0.25)%>%\n",
    "  layer_flatten() %>%\n",
    "  layer_dense(units=64, activation = 'relu')%>%\n",
    "  layer_dropout(rate=0.2)%>%\n",
    "  layer_dense(units=32, activation='relu')%>%\n",
    "  layer_dropout(rate=0.2) %>%\n",
    "  layer_dense(units=1, activation='sigmoid')%>%\n",
    "  compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=c('accuracy')\n",
    "  )\n",
    "summary(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "conv3d_1 (Conv3D)                   (None, 2, 126, 70, 50)          4100        \n",
      "________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)      (None, 1, 63, 35, 50)           0           \n",
      "________________________________________________________________________________\n",
      "flatten_6 (Flatten)                 (None, 110250)                  0           \n",
      "________________________________________________________________________________\n",
      "dropout_12 (Dropout)                (None, 110250)                  0           \n",
      "________________________________________________________________________________\n",
      "dense_16 (Dense)                    (None, 64)                      7056064     \n",
      "________________________________________________________________________________\n",
      "dropout_13 (Dropout)                (None, 64)                      0           \n",
      "________________________________________________________________________________\n",
      "dense_17 (Dense)                    (None, 32)                      2080        \n",
      "________________________________________________________________________________\n",
      "dropout_14 (Dropout)                (None, 32)                      0           \n",
      "________________________________________________________________________________\n",
      "dense_18 (Dense)                    (None, 1)                       33          \n",
      "================================================================================\n",
      "Total params: 7,062,277\n",
      "Trainable params: 7,062,277\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN <- keras_model_sequential()\n",
    "\n",
    "RNN %>% layer_conv_3d(filters=50, kernel_size = c(3,3,3), \n",
    "                           input_shape = c(4,128,72,3), \n",
    "                           data_format = \"channels_last\",\n",
    "                           activation=\"relu\") %>%\n",
    "  layer_max_pooling_3d(pool_size = c(2,2,2)) %>%\n",
    "  layer_flatten()%>%\n",
    "  layer_dropout(rate=0.25)%>%\n",
    "  layer_dense(units=64, activation = 'relu')%>%\n",
    "  layer_dropout(rate=0.2)%>%\n",
    "  layer_dense(units=32, activation='relu')%>%\n",
    "  layer_dropout(rate=0.2) %>%\n",
    "  layer_dense(units=1, activation='sigmoid')%>%\n",
    "  compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=c('accuracy')\n",
    "  )\n",
    "summary(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 LRCN Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a long-term reccurent convolution network (LRCN) framework was used, by converting events into 7 second clips, and fitting time distributed CNNs and RNNS to evaluate them. The same approach was used for both sex and behaviour classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "time_distributed_9 (TimeDistributed (None, 36, 4, 2, 512)           20024384    \n",
      "________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistribute (None, 36, 4096)                0           \n",
      "________________________________________________________________________________\n",
      "dropout_21 (Dropout)                (None, 36, 4096)                0           \n",
      "________________________________________________________________________________\n",
      "lstm_1 (LSTM)                       (None, 64)                      1065216     \n",
      "________________________________________________________________________________\n",
      "dropout_22 (Dropout)                (None, 64)                      0           \n",
      "________________________________________________________________________________\n",
      "dense_22 (Dense)                    (None, 64)                      4160        \n",
      "________________________________________________________________________________\n",
      "dropout_23 (Dropout)                (None, 64)                      0           \n",
      "________________________________________________________________________________\n",
      "dense_23 (Dense)                    (None, 32)                      2080        \n",
      "________________________________________________________________________________\n",
      "dropout_24 (Dropout)                (None, 32)                      0           \n",
      "________________________________________________________________________________\n",
      "dense_24 (Dense)                    (None, 1)                       33          \n",
      "================================================================================\n",
      "Total params: 21,095,873\n",
      "Trainable params: 21,095,873\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LRCNModel <- keras_model_sequential()%>%\n",
    "  time_distributed(VGG19, input_shape = c(36,128,72,3)) %>%\n",
    "  time_distributed(layer_flatten(), input_shape = c(36,4,2,512))%>%\n",
    "  layer_dropout(rate=0.2)%>%\n",
    "  layer_lstm(units=64,input_shape = c(36,4096))%>%\n",
    "  layer_dropout(rate=0.2)%>%\n",
    "  layer_dense(units=64, activation='relu')%>%\n",
    "  layer_dropout(rate=0.2)%>%\n",
    "  layer_dense(units=32, activation='relu')%>%\n",
    "  layer_dropout(rate=0.2)%>%\n",
    "  layer_dense(units=1, activation='sigmoid')%>%\n",
    "  compile(\n",
    "    optimizer=optimizer_adam(lr=1e-05),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=c('accuracy')\n",
    "  )\n",
    "\n",
    "summary(LRCNModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
